Assignment 4
============
README.md - Sivanujann Selliah - s093042 - 27/01/13

The following are reflections on profiling different features available in Objective-C.

The profiling task was two-fold; one was to profile the computation times of different features and the second was to profile the memory allocation involved when using these features.

The tools used were Instruments, where the Time profiler and the Allocations instruments were used; the other tool used was the Terminal which was used to execute and run the binaries with different number of iterations and elements.

Regarding the data from the Time profiler from Instruments, because both the Time profiler and the Allocations instruments were put in the same suite and run simultaneously, the computation times takes a little longer than usually, this is because the Allocation instrument, injects code to be executed, when objects are allocated or de-allocated, the times can still however be used to figure out where the execution control uses the most time. But to be able to get more precise computation timing on the different features, they have also been run in the Terminal, where each operation has been timed using the `NSDate` and `NSTimeInterval` objects, which will print out the execution time of a set of operations in milliseconds.

Code for the profiling is found in this directory. Data from the profiling is found in the Data folder: the data from Instruments is found in [Data/Instruments/](assignment4/Data/Instruments/ "Link to Data/Instruments/") and output from the Terminal is found in [Data/Terminal/](assignment4/Data/Terminal/ "Link to Data/Terminal/").

It might be a good idea to look, at least at the "main.m" file in each project to see what is being profiled, when reading the following, and maybe looking at the raw data, or just the output from the Terminal.

String manipulation
-------------------
The data from the execution of the program "StringManipulation" ranging from 100 to 10 000 000 append operations to a `NSMutableString` object shows, that the complexity is linear to the number of operations; using the data from the 10 000 000 operation run, shows that using the `appendString` method once takes: (3253.894031 milliseconds) / 10 000 000 = 325.389403 nanoseconds. The Time profiler indicates that most of the computation time is spent in the `appendString` method, but more interestingly is it maybe to see the data from the Allocations instrument, which shows that a total of 233 allocations of a total of 79.62 KB memory was allocated during the execution of the program. The data from Instruments are based on the default of using 10 000 append operations.

The data from the execution of the program "LevenshteinDistance" with two random strings each of a size ranging from 1 to 11 showed that the complexity of finding the distance is exponential. More interesting data was found using the Time profiler, where the recursion was flatten, so the time used on individual methods could be presented better; the data showed that most of the computation time was used on the `substringToIndex` method. The Allocations instrument showed that a total of 14647 allocations were made, allocating a total of 616.62 KB memory; most of these allocations were made by the category (CFString (immutable)), where a total of 14368 allocations were made with a total use of 449.09 KB memory. The data from Instruments are based on two strings of the default size of 7.

Heavy use of recursion
----------------------
No testing was done to profile the performance of heavy use of recursion.

Heap trashing and thrashing
---------------------------
No testing was done to profile the performance of the heavy use of the heap.

Method invocation costs
-----------------------
The data from the execution of the program "MethodInvocation" using 10 000 000 iterations, showed some interesting differences in the different ways of invoking a method. Calling an instance method 10 000 000  times using brackets took 249.397993 ms, while calling a class method 10 000 000 times  also using brackets took 171.761036 ms. Calling an instance method using selectors 10 000 000 times took 241.192997 ms, while calling a class method using selectors 10 000 000 times took 274.281025 ms. When using introspection and calling an instance method 10 000 000 times took 819.984019 ms, while when using introspection and calling a class method 10 000 000 times took 610.400975 ms.  So there might be some subtle differences in the times it takes to invoke an instance method versus a class method, but this is a very little difference even when invoking them 10 000 000 times. There is a much more noticeable difference when using introspection where it takes longer to verify that an instance method can be called than verifying whether a class method can be called. The execution of "MethodInvocation" also included tests on the different property access methods; getting a property 10 000 000 times using dot-syntax took 124.804974 ms while using bracket calls to get a property 10 000 000 times  took 127.638996 ms. So there really is no difference whether one uses one form over the other, at least not if it is over performance concerns.

The "MethodInvocation" was also profiled using Instruments, where the Time profiler clearly shows that the methods `respondsToSelector` and `performSelector` are the methods that takes the most time executing in the program with the default of 100 000 iterations.

Enumerations and iteration
--------------------------
The data from the execution of the program "EnumerationIteration" using 10 000 000 ordered elements showed that using normal iteration for enumeration using bracket syntax (`array[index]`) took 644.484997 ms while using the method ` objectAtIndex` took 592.447996 ms, so it seems like the convenience method of using bracket syntax is a little slower, but considering the number of elements, this is a very little performance difference. Something that does have a huge performance difference is using enumeration with a `while`-loop, which took 826.070011 ms for enumerating through 10 000 000 ordered elements, while when using "fast enumeration" this only took 83.378017 ms. So "fast enumeration" is almost 10 times faster than using a `while`-loop, and almost 7 times faster than using a `for`-loop and using the `objectAtIndex` method. Looking at the data from the Time profiler, it is seen that getting an instance of the enumerator is what takes the most time.

The data from the execution of the program "MatrixMultiplication" ranging from matrices of size 10 x 10 to 100 x 100, showed that the complexity of the implemented matrix multiplication had a powered growth rate. The data from Instruments shows something more interesting, e.g. the Time profiler shows that most time was used on the `numberWithDouble` factory method of `NSNumber`. The Allocations instrument also shows that most allocations were made by the category "CFNumber" with a total of 33125 allocations, with a total use of 1.01 MB of memory, and the whole program used a total of 33965 allocations with a total use of 1.36 MB memory allocated, with the default of multipliying two 25 x 25 matrices. "CFNumber" is what holds C scalar types and is used by `NSNumber`.

Foundation Framework classes
----------------------------
The data from executing the program "FoundationFrameworkClasses" with 1000 iterations and a range from 100 to 1 000 000 elements showed, that using the Objective-C "native" wrappers for integers takes more time to use: using `NSUInteger` and using `NSNumber` to hold the value took 0.205994 ms, while a 1000 iterations of using `int` and holding the value in `int` took 0.020981 ms, this just shows that using a reference type is more expensive than using a primitive type. Another frequently used class from the Foundation Framework is `NSString`, which took 0.268042 ms to copy 1000 times, so one copy operation would in average take 268.042 nanoseconds. The double number factory that we saw used earlier, was also tested, and the test showed that calling the `numberWithDouble` factory method of `NSNumber` took 0.465989 ms to call 1000 times, i.e. on average it would take 465.989 nanoseconds to execute the factory method. The ranging number of elements was used for testing the `count` method of the two types of arrays `NSArray` and `NSMutableArray`, where it was shown that calling the `count` method on any number of elements is very constant, and that there is nearly no performance difference on calling the `count` method, from the two types of arrays. The ranging number of elements was also used to performance test the `objectForKey` method for the two types of dictionaries `NSDictionary` and `NSMutableDictionary`, again it was seen that the complexities are nearly constant (apart from the two tests with small sets of elements), and that there is nearly no performance difference between using the mutable and the immutable version. These tests have shown that the mutable subclasses perform just as good as the immutable on some operations. The Allocations instrument showed that running this program with the default of 10 000 iterations and 100 elements, used allocation of strings very heavily (almost 70 MB worth), which shows that one probably should not use that many strings in an application, although an average laptop can hold much more...

Blocks
------
The data from executing the program "Blocks", with 10 000 000 iterations showed that there is nearly no difference between using a small or large block, which took 610.490024 ms and 668.339968 ms to execute, respectively.  A much more interesting test showed that it took 3733.036995 ms to declare and call 10 000 000 blocks with a bound variable (an integer variable), while it only took 484.587014 ms to declare and call 10 000 000 blocks with an "internal" variable (also an integer variable, but inside the scope of the block). Also using "external" variables using `__block` was shown to be using more computation time, i.e. when using such an "external" variable in a block took 1671.571016 ms for  10 000 000 iterations, while the same number of iterations, using an "internal" variable only took 793.789029 ms. The performance testing also included tests for bound and free variables of both reference type and primitive type variables, where it was shown that using bound primitive variables uses less time than using bound reference type variables, 10 000 000 iterations took 1646.928966 ms and 2067.318976 ms, respectively. Again it was shown that "internal"/"free" variables took less time than the bound variables, and here the same pattern of primitive type variables using less computation time than reference type variables: 619.695008 ms and 1760.949969 ms for 10 000 000 iterations, respectively. The Time profiler showed that Objective-C use `__NSMallocBlock` to retain blocks in memory.

Protocols
---------
The data from executing the program "Protocols" using 1 000 000 iterations show that using a small protocol versus a large protocol nearly has no difference, it also showed that allocating and using a small versus allocating and using a large protocol does not have any real difference either. Another area that showed no real difference performance-wise was using one versus multiple protocols. But there was a slight performance difference when allocation of one versus multiple protocols was put together with the usage: it took 470.701993 ms to execute 1 000 000 iterations of allocating and using only one protocol while it took 563.013971 ms to execute the same number of iterations of allocating and using multiple protocols. The Allocation instrument showed that the use of protocols took quite a lot of memory, each protocol took about 53 MB of memory for 100 000 iterations of allocating each, so an excess use of protocols (allocating and de-allocating hundreds of thousands (which no application really does...)), might not be a good idea. Overall there does not seem to be any significant performance differences whether one uses one small or multiple large protocols.

Concluding remark
-----------------
As it is seen above a lot of the "interesting" profiling first occur when executing the operations millions of times. This shows that most of these performance "concerns" might not be so relevant on average applications running on average computers or devices.
